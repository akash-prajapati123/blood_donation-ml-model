{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "60d549c0",
   "metadata": {},
   "source": [
    "## 1. Inspecting transfusion.data file\n",
    "<p><img src=\"https://assets.datacamp.com/production/project_646/img/blood_donation.png\" style=\"float: right;\" alt=\"A pictogram of a blood bag with blood donation written in it\" width=\"200\"></p>\n",
    "<p>Blood transfusion saves lives - from replacing lost blood during major surgery or a serious injury to treating various illnesses and blood disorders. Ensuring that there's enough blood in supply whenever needed is a serious challenge for the health professionals. According to <a href=\"https://www.webmd.com/a-to-z-guides/blood-transfusion-what-to-know#1\">WebMD</a>, \"about 5 million Americans need a blood transfusion every year\".</p>\n",
    "<p>Our dataset is from a mobile blood donation vehicle in Taiwan. The Blood Transfusion Service Center drives to different universities and collects blood as part of a blood drive. We want to predict whether or not a donor will give blood the next time the vehicle comes to campus.</p>\n",
    "<p>The data is stored in <code>datasets/transfusion.data</code> and it is structured according to RFMTC marketing model (a variation of RFM). We'll explore what that means later in this notebook. First, let's inspect the data.</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e464c4da",
   "metadata": {},
   "source": [
    "## 2. Loading the blood donations data\n",
    "<p>We now know that we are working with a typical CSV file (i.e., the delimiter is <code>,</code>, etc.). We proceed to loading the data into memory.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fdb856ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Recency (months)</th>\n",
       "      <th>Frequency (times)</th>\n",
       "      <th>Monetary (c.c. blood)</th>\n",
       "      <th>Time (months)</th>\n",
       "      <th>whether he/she donated blood in March 2007</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>50</td>\n",
       "      <td>12500</td>\n",
       "      <td>98</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>3250</td>\n",
       "      <td>28</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>16</td>\n",
       "      <td>4000</td>\n",
       "      <td>35</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>20</td>\n",
       "      <td>5000</td>\n",
       "      <td>45</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>24</td>\n",
       "      <td>6000</td>\n",
       "      <td>77</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Recency (months)  Frequency (times)  Monetary (c.c. blood)  Time (months)  \\\n",
       "0                 2                 50                  12500             98   \n",
       "1                 0                 13                   3250             28   \n",
       "2                 1                 16                   4000             35   \n",
       "3                 2                 20                   5000             45   \n",
       "4                 1                 24                   6000             77   \n",
       "\n",
       "   whether he/she donated blood in March 2007  \n",
       "0                                           1  \n",
       "1                                           1  \n",
       "2                                           1  \n",
       "3                                           1  \n",
       "4                                           0  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import pandas\n",
    "import pandas as pd\n",
    "\n",
    "# Read in dataset\n",
    "transfusion =pd.read_csv(\"datasets/transfusion.data\")\n",
    "\n",
    "# Print out the first rows of our dataset\n",
    "transfusion.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e6daf97",
   "metadata": {},
   "source": [
    "## 3. Inspecting transfusion DataFrame\n",
    "<p>Let's briefly return to our discussion of RFM model. RFM stands for Recency, Frequency and Monetary Value and it is commonly used in marketing for identifying your best customers. In our case, our customers are blood donors.</p>\n",
    "<p>RFMTC is a variation of the RFM model. Below is a description of what each column means in our dataset:</p>\n",
    "<ul>\n",
    "<li>R (Recency - months since the last donation)</li>\n",
    "<li>F (Frequency - total number of donation)</li>\n",
    "<li>M (Monetary - total blood donated in c.c.)</li>\n",
    "<li>T (Time - months since the first donation)</li>\n",
    "<li>a binary variable representing whether he/she donated blood in March 2007 (1 stands for donating blood; 0 stands for not donating blood)</li>\n",
    "</ul>\n",
    "<p>It looks like every column in our DataFrame has the numeric type, which is exactly what we want when building a machine learning model. Let's verify our hypothesis.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1ffdb16d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 748 entries, 0 to 747\n",
      "Data columns (total 5 columns):\n",
      " #   Column                                      Non-Null Count  Dtype\n",
      "---  ------                                      --------------  -----\n",
      " 0   Recency (months)                            748 non-null    int64\n",
      " 1   Frequency (times)                           748 non-null    int64\n",
      " 2   Monetary (c.c. blood)                       748 non-null    int64\n",
      " 3   Time (months)                               748 non-null    int64\n",
      " 4   whether he/she donated blood in March 2007  748 non-null    int64\n",
      "dtypes: int64(5)\n",
      "memory usage: 29.3 KB\n"
     ]
    }
   ],
   "source": [
    "# Print a concise summary of transfusion DataFrame\n",
    "transfusion.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58fdc4f3",
   "metadata": {},
   "source": [
    "## 4. Creating target column\n",
    "<p>We are aiming to predict the value in <code>whether he/she donated blood in March 2007</code> column. Let's rename this it to <code>target</code> so that it's more convenient to work with.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "94c9fd59",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Recency (months)</th>\n",
       "      <th>Frequency (times)</th>\n",
       "      <th>Monetary (c.c. blood)</th>\n",
       "      <th>Time (months)</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>50</td>\n",
       "      <td>12500</td>\n",
       "      <td>98</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>3250</td>\n",
       "      <td>28</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Recency (months)  Frequency (times)  Monetary (c.c. blood)  Time (months)  \\\n",
       "0                 2                 50                  12500             98   \n",
       "1                 0                 13                   3250             28   \n",
       "\n",
       "   target  \n",
       "0       1  \n",
       "1       1  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Rename target column as 'target' for brevity \n",
    "transfusion.rename(\n",
    "    columns={'whether he/she donated blood in March 2007': 'target'},\n",
    "    inplace=True\n",
    ")\n",
    "\n",
    "# Print out the first 2 rows\n",
    "\n",
    "transfusion.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d86078e",
   "metadata": {},
   "source": [
    "## 5. Checking target incidence\n",
    "<p>We want to predict whether or not the same donor will give blood the next time the vehicle comes to campus. The model for this is a binary classifier, meaning that there are only 2 possible outcomes:</p>\n",
    "<ul>\n",
    "<li><code>0</code> - the donor will not give blood</li>\n",
    "<li><code>1</code> - the donor will give blood</li>\n",
    "</ul>\n",
    "<p>Target incidence is defined as the number of cases of each individual target value in a dataset. That is, how many 0s in the target column compared to how many 1s? Target incidence gives us an idea of how balanced (or imbalanced) is our dataset.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8ab9f03c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0.762\n",
       "1    0.238\n",
       "Name: target, dtype: float64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Print target incidence proportions, rounding output to 3 decimal places\n",
    "\n",
    "transfusion.target.value_counts(normalize=True).round(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c178c41d",
   "metadata": {},
   "source": [
    "## 6. Splitting transfusion into train and test datasets\n",
    "<p>We'll now use <code>train_test_split()</code> method to split <code>transfusion</code> DataFrame.</p>\n",
    "<p>Target incidence informed us that in our dataset <code>0</code>s appear 76% of the time. We want to keep the same structure in train and test datasets, i.e., both datasets must have 0 target incidence of 76%. This is very easy to do using the <code>train_test_split()</code> method from the <code>scikit learn</code> library - all we need to do is specify the <code>stratify</code> parameter. In our case, we'll stratify on the <code>target</code> column.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bd228a29",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Recency (months)</th>\n",
       "      <th>Frequency (times)</th>\n",
       "      <th>Monetary (c.c. blood)</th>\n",
       "      <th>Time (months)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>334</th>\n",
       "      <td>16</td>\n",
       "      <td>2</td>\n",
       "      <td>500</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>1750</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Recency (months)  Frequency (times)  Monetary (c.c. blood)  Time (months)\n",
       "334                16                  2                    500             16\n",
       "99                  5                  7                   1750             26"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Split transfusion DataFrame into\n",
    "# X_train, X_test, y_train and y_test datasets,\n",
    "# stratifying on the `target` column\n",
    "X_train,X_test,y_train,y_test= train_test_split(\n",
    "    transfusion.drop(columns='target'),\n",
    "    transfusion.target,\n",
    "    test_size=0.25,\n",
    "    random_state=42,\n",
    "    stratify=transfusion.target\n",
    ")\n",
    "\n",
    "# Print out the first 2 rows of X_train\n",
    "\n",
    "X_train.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "822f0d1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Logistic Regression AUC score: 0.7851\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "\n",
    "# Logistic Regression\n",
    "logreg = LogisticRegression(solver='liblinear', random_state=42)\n",
    "logreg.fit(X_train, y_train)\n",
    "\n",
    "# AUC score\n",
    "logreg_auc_score = roc_auc_score(y_test, logreg.predict_proba(X_test)[:, 1])\n",
    "print(f'\\nLogistic Regression AUC score: {logreg_auc_score:.4f}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f822c94c",
   "metadata": {},
   "source": [
    "## 7. Checking the Variance\n",
    "\n",
    "TPOT picked LogisticRegression as the best model for our dataset with no pre-processing steps, giving us the AUC score of 0.7850. This is a great starting point. Let's see if we can make it better.\n",
    "\n",
    "One of the assumptions for linear models is that the data and the features we are giving it are related in a linear fashion, or can be measured with a linear distance metric. If a feature in our dataset has a high variance that's orders of magnitude greater than the other features, this could impact the model's ability to learn from other features in the dataset.\n",
    "\n",
    "Correcting for high variance is called normalization. It is one of the possible transformations you do before training a model. Let's check the variance to see if such transformation is needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "42c0f1ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Recency (months)              66.929\n",
       "Frequency (times)             33.830\n",
       "Monetary (c.c. blood)    2114363.700\n",
       "Time (months)                611.147\n",
       "dtype: float64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.var().round(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4cc45ed",
   "metadata": {},
   "source": [
    "## 8. Log normalization\n",
    "<p><code>Monetary (c.c. blood)</code>'s variance is very high in comparison to any other column in the dataset. This means that, unless accounted for, this feature may get more weight by the model (i.e., be seen as more important) than any other feature.</p>\n",
    "<p>One way to correct for high variance is to use log normalization.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3ad4053b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Recency (months)      66.929\n",
       "Frequency (times)     33.830\n",
       "Time (months)        611.147\n",
       "monetary_log           0.837\n",
       "dtype: float64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import numpy\n",
    "import numpy as np\n",
    "\n",
    "# Copy X_train and X_test into X_train_normed and X_test_normed\n",
    "X_train_normed,X_test_normed = X_train.copy(), X_test.copy()\n",
    "\n",
    "# Specify which column to normalize\n",
    "col_to_normalize ='Monetary (c.c. blood)'\n",
    "\n",
    "# Log normalization\n",
    "for df_ in [X_train_normed, X_test_normed]:\n",
    "    # Add log normalized column\n",
    "    df_['monetary_log'] = np.log(df_[col_to_normalize])\n",
    "    # Drop the original column\n",
    "    df_.drop(columns=col_to_normalize, inplace=True)\n",
    "\n",
    "# Check the variance for X_train_normed\n",
    "\n",
    "X_train_normed.var().round(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "80bf5cd2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Logistic Regression AUC score: 0.7891\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "# Logistic Regression\n",
    "logreg = LogisticRegression(solver='liblinear', random_state=42)\n",
    "logreg.fit(X_train_normed, y_train)\n",
    "\n",
    "# AUC score\n",
    "logreg_auc_score = roc_auc_score(y_test, logreg.predict_proba(X_test_normed)[:, 1])\n",
    "print(f'\\nLogistic Regression AUC score: {logreg_auc_score:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2af72dc3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Random Forest AUC score: 0.7116\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Random Forest\n",
    "rf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "rf.fit(X_train_normed, y_train)\n",
    "\n",
    "# AUC score\n",
    "rf_auc_score = roc_auc_score(y_test, rf.predict_proba(X_test_normed)[:, 1])\n",
    "print(f'\\nRandom Forest AUC score: {rf_auc_score:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "47f020fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 10 candidates, totalling 30 fits\n",
      "Best Parameters:  {'subsample': 0.6, 'n_estimators': 50, 'min_child_weight': 5, 'max_depth': 3, 'learning_rate': 0.2, 'gamma': 0, 'colsample_bytree': 1.0}\n",
      "Best Accuracy Score:  0.7825311942959002\n",
      "\n",
      "Optimized XGBoost AUC score: 0.7778\n",
      "\n",
      "Optimized XGBoost accuracy: 0.7647\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kumar\\AppData\\Roaming\\Python\\Python310\\site-packages\\xgboost\\sklearn.py:889: UserWarning: `eval_metric` in `fit` method is deprecated for better compatibility with scikit-learn, use `eval_metric` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n",
      "C:\\Users\\kumar\\AppData\\Roaming\\Python\\Python310\\site-packages\\xgboost\\sklearn.py:889: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import numpy as np\n",
    "\n",
    "param_grid = {\n",
    "    'n_estimators': [50, 100, 200],  # Number of boosting rounds\n",
    "    'learning_rate': [0.01, 0.1, 0.2],  # Step size shrinkage\n",
    "    'max_depth': [3, 5, 7],  # Maximum tree depth\n",
    "    'min_child_weight': [1, 3, 5],  # Minimum sum of instance weight (hessian)\n",
    "    'subsample': [0.6, 0.8, 1.0],  # Subsample ratio of training instances\n",
    "    'colsample_bytree': [0.6, 0.8, 1.0],  # Subsample ratio of columns when constructing each tree\n",
    "    'gamma': [0, 0.1, 0.2]  # Minimum loss reduction required to make a further partition\n",
    "}\n",
    "\n",
    "# Create the XGBoost classifier\n",
    "xgb = XGBClassifier(random_state=42)\n",
    "\n",
    "# Set up RandomizedSearchCV with 10 iterations and 3-fold cross-validation to save time\n",
    "random_search = RandomizedSearchCV(estimator=xgb, \n",
    "                                   param_distributions=param_grid, \n",
    "                                   n_iter=10,  # Number of parameter settings to sample\n",
    "                                   cv=3,  # 3-fold cross-validation\n",
    "                                   scoring='accuracy', \n",
    "                                   verbose=1,  # Increase verbosity to get updates\n",
    "                                   random_state=42, \n",
    "                                   n_jobs=-1)  # Use all available cores\n",
    "\n",
    "# Fit the random search on the training data\n",
    "random_search.fit(X_train, y_train)\n",
    "\n",
    "# Output the best parameters and the best score\n",
    "print(\"Best Parameters: \", random_search.best_params_)\n",
    "print(\"Best Accuracy Score: \", random_search.best_score_)\n",
    "\n",
    "# Train the XGBoost model with the best parameters found by RandomizedSearchCV\n",
    "best_xgb = random_search.best_estimator_\n",
    "best_xgb.fit(X_train_normed, y_train, eval_set=[(X_test_normed, y_test)], eval_metric=\"auc\", early_stopping_rounds=10, verbose=False)\n",
    "\n",
    "# Predict and calculate the AUC score on the test set\n",
    "xgb_auc_score = roc_auc_score(y_test, best_xgb.predict_proba(X_test_normed)[:, 1])\n",
    "print(f'\\nOptimized XGBoost AUC score: {xgb_auc_score:.4f}')\n",
    "\n",
    "# Accuracy score\n",
    "accuracy = best_xgb.score(X_test_normed, y_test)\n",
    "print(f'\\nOptimized XGBoost accuracy: {accuracy:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "245b997e",
   "metadata": {},
   "source": [
    "## 9. Selecting model using TPOT\n",
    "<p><a href=\"https://github.com/EpistasisLab/tpot\">TPOT</a> is a Python Automated Machine Learning tool that optimizes machine learning pipelines using genetic programming.</p>\n",
    "<p><img src=\"https://assets.datacamp.com/production/project_646/img/tpot-ml-pipeline.png\" alt=\"TPOT Machine Learning Pipeline\"></p>\n",
    "<p>TPOT will automatically explore hundreds of possible pipelines to find the best one for our dataset. Note, the outcome of this search will be a <a href=\"https://scikit-learn.org/stable/modules/generated/sklearn.pipeline.Pipeline.html\">scikit-learn pipeline</a>, meaning it will include any pre-processing steps as well as the model.</p>\n",
    "<p>We are using TPOT to help us zero in on one model that we can then explore and optimize further.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "35df9375",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Optimization Progress:   0%|          | 0/120 [00:00<?, ?pipeline/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Generation 1 - Current best internal CV score: 0.7425140598875208\n",
      "\n",
      "Generation 2 - Current best internal CV score: 0.7425140598875208\n",
      "\n",
      "Generation 3 - Current best internal CV score: 0.7425140598875208\n",
      "\n",
      "Generation 4 - Current best internal CV score: 0.7425140598875208\n",
      "\n",
      "Generation 5 - Current best internal CV score: 0.7442353486813131\n",
      "\n",
      "Best pipeline: LogisticRegression(GaussianNB(ZeroCount(input_matrix)), C=25.0, dual=False, penalty=l2)\n",
      "\n",
      "AUC score: 0.7939\n",
      "\n",
      "Best pipeline steps:\n",
      "1. ZeroCount()\n",
      "2. StackingEstimator(estimator=GaussianNB())\n",
      "3. LogisticRegression(C=25.0, random_state=42)\n"
     ]
    }
   ],
   "source": [
    "# Import TPOTClassifier and roc_auc_score\n",
    "from tpot import TPOTClassifier\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "# Instantiate TPOTClassifier\n",
    "tpot = TPOTClassifier(\n",
    "    generations=5,\n",
    "    population_size=20,\n",
    "    verbosity=2,\n",
    "    scoring='roc_auc',\n",
    "    random_state=42,\n",
    "    disable_update_check=True,\n",
    "    config_dict='TPOT light'\n",
    ")\n",
    "tpot.fit(X_train, y_train)\n",
    "\n",
    "# AUC score for tpot model\n",
    "tpot_auc_score = roc_auc_score(y_test, tpot.predict_proba(X_test)[:, 1])\n",
    "\n",
    "print(f'\\nAUC score: {tpot_auc_score:.4f}')\n",
    "\n",
    "\n",
    "# Print best pipeline steps\n",
    "print('\\nBest pipeline steps:', end='\\n')\n",
    "for idx, (name, transform) in enumerate(tpot.fitted_pipeline_.steps, start=1):\n",
    "    # Print idx and transform\n",
    "    print(f'{idx}. {transform}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8b681a6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "011134df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7938652256834076\n"
     ]
    }
   ],
   "source": [
    "accuracy = tpot.score(X_test, y_test)\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "0616d37b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True values: 41     0\n",
      "682    0\n",
      "532    0\n",
      "538    1\n",
      "153    1\n",
      "      ..\n",
      "621    0\n",
      "371    0\n",
      "484    0\n",
      "655    0\n",
      "577    0\n",
      "Name: target, Length: 187, dtype: int64\n",
      "Predicted values: [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 1 0 0 0 0 0 0 0\n",
      " 0 0]\n"
     ]
    }
   ],
   "source": [
    "# Assuming 'topt' is your trained model (e.g., from TPOT or another training process)\n",
    "\n",
    "# Predict on the test set\n",
    "pred = tpot.predict(X_test)\n",
    "\n",
    "# Print the true values (y_test) and predicted values (pred)\n",
    "print(\"True values:\", y_test)\n",
    "print(\"Predicted values:\", pred)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "00f33a8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     True Values  Predicted Values\n",
      "41             0                 0\n",
      "682            0                 0\n",
      "532            0                 0\n",
      "538            1                 0\n",
      "153            1                 0\n",
      "..           ...               ...\n",
      "621            0                 0\n",
      "371            0                 0\n",
      "484            0                 0\n",
      "655            0                 0\n",
      "577            0                 0\n",
      "\n",
      "[187 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df_comparison = pd.DataFrame({\n",
    "    'True Values': y_test,\n",
    "    'Predicted Values': pred\n",
    "})\n",
    "\n",
    "# Display the DataFrame\n",
    "print(df_comparison)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5759eab7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
